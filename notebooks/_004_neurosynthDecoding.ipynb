{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurosynth decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Wir machen uns eine Liste mit allen unseren Hirnbildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgList = ['../meanTraining/%s'%x for x in os.listdir('../meanTraining/')]; imgList.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole-Brain Maske\n",
    "\n",
    "Hier benutzen wir eine grobe Maske mit 4mm Auflösung, weil die Berechnungen sonst zu lange dauern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting, input_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Maske habe ich vorbereitet, die laden wir als hinterlegtes Objekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_masker = pickle.load( open( \"../pickels/my4mm_masker.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NiftiMasker(detrend=False, high_pass=None, low_pass=None, mask_args=None,\n",
       "      mask_img='../rois/gmMap4mm.nii.gz', mask_strategy='background',\n",
       "      memory=Memory(cachedir=None), memory_level=1, sample_mask=None,\n",
       "      sessions=None, smoothing_fwhm=None, standardize=False, t_r=None,\n",
       "      target_affine=None, target_shape=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(my_masker.mask_img_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMaps(fileName,my_masker):\n",
    "    thisData = my_masker.transform(fileName)[-1]\n",
    "    scaleData = preprocessing.scale(thisData)\n",
    "    return scaleData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Ganze erstmal beispielhaft durchzugehen, nehmen wir uns einen einzelnen Block aus unseren Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisMap = imgList[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../meanTraining/meanCond_words.nii.gz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NiftiMasker' object has no attribute '_shelving'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6eef08e25d9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaleMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractMaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisMap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_masker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-203071922d5c>\u001b[0m in \u001b[0;36mextractMaps\u001b[0;34m(fileName, my_masker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextractMaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_masker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mthisData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_masker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscaleData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscaleData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/nilearn/input_data/base_masker.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_single_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/nilearn/input_data/nifti_masker.pyc\u001b[0m in \u001b[0;36mtransform_single_imgs\u001b[0;34m(self, imgs, confounds, copy)\u001b[0m\n\u001b[1;32m    285\u001b[0m                            ignore=['verbose', 'memory', 'memory_level',\n\u001b[1;32m    286\u001b[0m                                    'copy'],\n\u001b[0;32m--> 287\u001b[0;31m                            \u001b[0mshelve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shelving\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NiftiMasker' object has no attribute '_shelving'"
     ]
    }
   ],
   "source": [
    "scaleMap = extractMaps(thisMap,my_masker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wir laden ca. 600 Karten aus Neurosynth, die ich vorher ausgewählt habe  \n",
    "\n",
    "Die Einschlusskriterien waren, dass die Maske nicht leer sein darf (Stichwörter wie \"magnetic\" sind so unspefifisch, dass sie keine Voxel enthalten; außerdem gibt es sehr viele Karten, die zwar Voxel enthalten, aber keinem inhaltlich interpertierbaren psychologischen Prozess zugeordnet werden können (z.B. white matter, young, old, patient, healthy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsData = pd.read_csv('../arrays/ns_4mm_database.csv',index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterNames =  pickle.load( open( \"../pickels/clusterDict.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korrelation eines Blocks unserer Daten mit allen 602 Karten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thisCorr = np.corrcoef(scaleMap,nsData)[0,:][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisCorrDf = pd.DataFrame(thisCorr,index=nsData.index,columns=['corr']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisCorrDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wir sortieren nach Stärke der Korrelation\n",
    "\n",
    "Sonst müssten wir die 602 Korrelationen einzeln durchgehen um bedeutsame Zusammenhänge zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop(corrDf):\n",
    "    sortDf = corrDf.copy()\n",
    "    sortDf = sortDf.T.sort_values(by=sortDf.index[-1],ascending=False)\n",
    "    topDf = pd.concat([sortDf[:5],sortDf[-5:]],axis=0)\n",
    "    topDf.columns = ['correlation']\n",
    "    topDf = topDf.round(2)\n",
    "    return topDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topDf = getTop(thisCorrDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel: Die fünf höchstn und die fünf niedrigsten Korrelationen des gewählten Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die 602 Karten in Neurosynth nach Ähnlichkeit gruppieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben gesagt, dass die 602 Karten in Cluster eingeteilt sind. Können wir das irgendwie darstellen? Ja, indem wir die 18744 Dimensionen (jeder Voxel ist eine Dimension) auf 2 Dimensionen projizieren. Dazu verwenden wir [Multidimensionale Skalierung](http://scikit-learn.org/stable/modules/manifold.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier verwenden wir Daten die ich vorbereitet habe\n",
    "dissDf = pd.read_csv('../arrays/dissDf.csv',index_col=[0])\n",
    "mdsPositions = np.array(pd.read_csv('../arrays/mdsDf.csv',index_col=[0]))\n",
    "mdsDf = pd.DataFrame(mdsPositions,index=dissDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acht Fraben für die acht Cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPalette = sns.color_palette('Set1',n_colors=8)\n",
    "sns.palplot(myPalette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laden von vorbereiteten Sachen\n",
    "mdsDf = pd.read_csv('../arrays/mdsDf.csv',index_col=[0])\n",
    "kDf = pd.read_csv('../arrays/kDf.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbildung erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNeighbors(mdsDf,p,added,notCloserThan=50):\n",
    "    \n",
    "    # coordinates of this keyword\n",
    "    thisDf = mdsDf.loc[p]\n",
    "    \n",
    "    # coordinates of all other keywords\n",
    "    otherDf = mdsDf.drop(p)\n",
    "    \n",
    "    # lenghts of adjacent and opposite\n",
    "    diffDf = abs(thisDf-otherDf)\n",
    "    \n",
    "    # lengths of hypoteneuse\n",
    "    distanceDf = np.sqrt(diffDf**2).sum(axis=1)\n",
    "    \n",
    "    # check if there are close distances\n",
    "    closeEncounters = distanceDf[distanceDf<notCloserThan].index\n",
    "    \n",
    "    # check if the close ones have already been labelled\n",
    "    for entry in closeEncounters:\n",
    "        if entry in added:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einstellungen für Abbildung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### der große Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpace(mdsDf,kDf,clusterNames,myPalette,closest,ax):\n",
    "\n",
    "    kPredictions = list(kDf['n'])\n",
    "    # loop both trough the positions and the predictions\n",
    "    for p,l in zip(mdsDf.index,kPredictions):\n",
    "        # show predictions from raw data on mds scaled data, the predictions are indicated by the color\n",
    "        ax.plot( mdsDf.ix[p]['0'],\n",
    "                     mdsDf.ix[p]['1'],\n",
    "                     'o',color=myPalette[l],\n",
    "                      markersize=12,alpha=0.8\n",
    "               )\n",
    "\n",
    "    added = []\n",
    "    mdsDf = mdsDf.sort_values(by='1')\n",
    "    # sorting by the x-dimension will fill the labels from right to left side\n",
    "    mdsDf = mdsDf.sort_values(by='0',ascending=False)\n",
    "    for p,x,y in zip(mdsDf.index,mdsDf['0'], mdsDf['1']):\n",
    "        l = kDf.loc[p]\n",
    "        if not findNeighbors(mdsDf,p,added,notCloserThan=closest):\n",
    "            ax.annotate(p, xy = (x, y),fontsize=16,alpha=0.8)\n",
    "            added.append(p)\n",
    "            \n",
    "    # dummy plot for labelling\n",
    "    for l in np.unique(kDf['n']):\n",
    "        ax.plot([],'o',color=myPalette[l],label=clusterNames[str(l)])\n",
    "    \n",
    "    # show the plot\n",
    "    sns.despine(left=True,bottom=True)\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    ax.legend(loc='lower left',bbox_to_anchor=(0.,0))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(16,16))\n",
    "ax = plotSpace(mdsDf,kDf,clusterNames,myPalette,0,ax)\n",
    "#plt.savefig('../figs/nsBallSparse.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(16,16))\n",
    "ax = plotSpace(mdsDf,kDf,clusterNames,myPalette,50,ax)\n",
    "plt.savefig('../figs/nsBallSparse.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## der Ball - Teil 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung der Korrelationen von 0 bis 1\n",
    "def makeMinMax(corrDf):\n",
    "    minMaxDf = pd.DataFrame( preprocessing.minmax_scale(corrDf,axis=1),\n",
    "                            index=corrDf.index,\n",
    "                            columns=corrDf.columns )\n",
    "    return minMaxDf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxDf = makeMinMax(thisCorrDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisCorrDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(2,1,figsize=(12,5))\n",
    "sns.distplot(thisCorrDf.T,ax=ax1)\n",
    "sns.distplot(minMaxDf,ax=ax2)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbildung machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFullCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,ax):\n",
    "\n",
    "    kPredictions = list(kDf['n'])\n",
    "    # loop both trough the positions and the predictions\n",
    "    for p,l in zip(mdsDf.index,kPredictions):\n",
    "        # show predictions from raw data on mds scaled data, the predictions are indicated by the color\n",
    "        ax.plot( mdsDf.ix[p]['0'],\n",
    "                     mdsDf.ix[p]['1'],\n",
    "                     'o',color=myPalette[l],\n",
    "                      markersize=minMaxDf.ix[l].ix[p]**3*50,\n",
    "                      alpha=0.7\n",
    "               )\n",
    "\n",
    "    for p,l,x,y in zip(mdsDf.index,kPredictions, mdsDf['0'], mdsDf['1']):\n",
    "        ax.annotate(p, xy = (x, y),\n",
    "                    fontsize=minMaxDf.ix[l].ix[p]**3*50,\n",
    "                    alpha=minMaxDf.ix[l].ix[p]**10)\n",
    "\n",
    "            \n",
    "    # dummy plot for labelling\n",
    "    for l in np.unique(kDf['n']):\n",
    "        ax.plot([],'o',color=myPalette[l],label=clusterNames[str(l)])\n",
    "    \n",
    "    # show the plot\n",
    "    sns.despine(left=True,bottom=True)\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    #ax.legend(loc='lower left',bbox_to_anchor=(1.5,0))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMeanCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,closest,ax):\n",
    "\n",
    "    # loop both trough the positions and the predictions\n",
    "    for p in mdsDf.index:\n",
    "        l = kDf['n'].loc[p]\n",
    "        # show predictions from raw data on mds scaled data, the predictions are indicated by the color\n",
    "        ax.plot( mdsDf.ix[p]['0'],\n",
    "                     mdsDf.ix[p]['1'],\n",
    "                     'o',color=myPalette[l],\n",
    "                      markersize=minMaxDf.ix[l].ix[p]**3*50,\n",
    "                      alpha=0.7\n",
    "               )\n",
    "\n",
    "    # to not omit the most important keywords, we move through the list by the order in minMaxDf\n",
    "    sortedIndex = minMaxDf.sort_values('corr',ascending=False).index.labels[1]\n",
    "    sortedNames = [minMaxDf.index.levels[1][x] for x in sortedIndex ]\n",
    "    print sortedNames[:10]\n",
    "    added = []\n",
    "    for p in sortedNames:\n",
    "        l = kDf['n'].loc[p]\n",
    "        x = mdsDf['0'].loc[p]\n",
    "        y = mdsDf['1'].loc[p]\n",
    "\n",
    "        if not findNeighbors(mdsDf,p,added,notCloserThan=closest):\n",
    "\n",
    "            thisVal = minMaxDf.ix[l].ix[p].values[-1]\n",
    "            \n",
    "            ax.annotate(p, xy = (x, y),\n",
    "                    fontsize=thisVal**3*50,\n",
    "                    alpha=thisVal**5)\n",
    "            added.append(p)\n",
    "\n",
    "    # dummy plot for labelling\n",
    "    for l in np.unique(kDf['n']):\n",
    "        ax.plot([],'o',color=myPalette[l],label=clusterNames[str(l)])\n",
    "    \n",
    "    # show the plot\n",
    "    sns.despine(left=True,bottom=True)\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    #ax.legend(loc='lower left',bbox_to_anchor=(1.5,0))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "plotMeanCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,0,ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "plotMeanCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,50,ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "plotMeanCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,100,ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMeanMindSpace(thisMap,closest=100,\n",
    "                  my_masker=my_masker,nsData=nsData,mdsDf=mdsDf,kDf=kDf,\n",
    "                  myPalette=myPalette,clusterNames=clusterNames):\n",
    "\n",
    "    scaleMap = extractMaps(thisMap,my_masker)\n",
    "\n",
    "    thisCorr = np.corrcoef(scaleMap,nsData)[0,:][1:]\n",
    "    \n",
    "    thisCorrDf = pd.DataFrame(thisCorr,index=nsData.index,columns=['corr']).T\n",
    "    \n",
    "    minMaxDf = makeMinMax(thisCorrDf)\n",
    "\n",
    "    fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "    \n",
    "    plotMeanCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,closest,ax)\n",
    "    \n",
    "    fullName = thisMap.split('/')[-1].split('.')[0]\n",
    "    nam = fullName.split('_')[-1]\n",
    "    plt.title(nam,fontsize=32)\n",
    "    \n",
    "    plt.savefig('../nsfigs/synth_%s.png'%fullName,bbox_inches='tight',dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for im in ['../meanTraining/%s'%x for x in os.listdir('../meanTraining/')]:\n",
    "    makeMeanMindSpace(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For single blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,ax):\n",
    "\n",
    "    # loop both trough the positions and the predictions\n",
    "    for p in mdsDf.index:\n",
    "        l = kDf['n'].loc[p]\n",
    "        # show predictions from raw data on mds scaled data, the predictions are indicated by the color\n",
    "        ax.plot( mdsDf.ix[p]['0'],\n",
    "                     mdsDf.ix[p]['1'],\n",
    "                     'o',color=myPalette[l],\n",
    "                      markersize=minMaxDf.ix[l].ix[p]**3*50,\n",
    "                      alpha=0.7\n",
    "               )\n",
    "\n",
    "    # to not omit the most important keywords, we move through the list by the order in minMaxDf\n",
    "    sortedIndex = minMaxDf.sort_values('corr',ascending=False).index.labels[1]\n",
    "    sortedNames = [minMaxDf.index.levels[1][x] for x in sortedIndex ]\n",
    "        \n",
    "    added = []\n",
    "    counter = 5\n",
    "    for p in sortedNames:\n",
    "        l = kDf['n'].loc[p]\n",
    "        x = mdsDf['0'].loc[p]\n",
    "        y = mdsDf['1'].loc[p]\n",
    "\n",
    "        if counter > 0:\n",
    "            if not findNeighbors(mdsDf,p,added,notCloserThan=130):\n",
    "\n",
    "                ax.annotate(p, xy = (x, y),\n",
    "                        fontsize=minMaxDf.ix[l].ix[p]**3*70,\n",
    "                        alpha=minMaxDf.ix[l].ix[p]**30*5)\n",
    "                added.append(p)\n",
    "                \n",
    "                counter-=1\n",
    "            \n",
    "    # dummy plot for labelling\n",
    "    for l in np.unique(kDf['n']):\n",
    "        ax.plot([],'o',color=myPalette[l],label=clusterNames[str(l)])\n",
    "    \n",
    "    # show the plot\n",
    "    sns.despine(left=True,bottom=True)\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    #ax.legend(loc='lower left',bbox_to_anchor=(1.5,0))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMindSpace(thisMap,\n",
    "                  my_masker=my_masker,nsData=nsData,mdsDf=mdsDf,kDf=kDf,\n",
    "                  myPalette=myPalette,clusterNames=clusterNames):\n",
    "\n",
    "    scaleMap = extractMaps(thisMap,my_masker)\n",
    "\n",
    "    thisCorr = np.corrcoef(scaleMap,nsData)[0,:][1:]\n",
    "    \n",
    "    thisCorrDf = pd.DataFrame(thisCorr,index=nsData.index,columns=['corr']).T\n",
    "    \n",
    "    minMaxDf = makeMinMax(thisCorrDf)\n",
    "\n",
    "    fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "    \n",
    "    plotCorr(mdsDf,kDf,minMaxDf,myPalette,clusterNames,ax)\n",
    "    \n",
    "    fullName = thisMap.split('/')[-1].split('.')[0]\n",
    "    nam = fullName.split('_')[-1]\n",
    "    num = fullName.split('_')[1]\n",
    "    plt.title('%s %s' % (num,nam),fontsize=72,y=1.04)\n",
    "    \n",
    "    plt.savefig('../nsfigs/synth_%s.png'%fullName,bbox_inches='tight',dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortBlocks(blocks):\n",
    "    d = {}\n",
    "    for i in blocks:\n",
    "        num = i.split('/')[-1].split('.')[0]\n",
    "        d[num] = i\n",
    "    sortRunDf = pd.DataFrame(d,index=['filename']).T\n",
    "    sortRunDf.sort_index(inplace=True)\n",
    "    return sortRunDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgList = ['../test/%s'%x for x in os.listdir('../test/')]; imgList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortRunDf = sortBlocks(imgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortRunDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in sortRunDf.index:\n",
    "    thisBlock = sortRunDf.ix[i]['filename']\n",
    "    makeMindSpace(thisBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballList = ['../nsfigs/%s'%x for x in os.listdir('../nsfigs/') if x.startswith('synth') and '_00' not in x and 'meanCond' not in x]\n",
    "ballList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in ballList:\n",
    "    im = Image.open(i)\n",
    "    thisAspect = im.getbbox()\n",
    "    a.append(thisAspect)\n",
    "    \n",
    "whereMax = pd.DataFrame(a).idxmax(axis=0).max()\n",
    "maxSize = tuple( pd.DataFrame(a).loc[whereMax]+2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,14))\n",
    "for i,im in enumerate(ballList):\n",
    "    ax = plt.subplot(5,5,i+1)\n",
    "    \n",
    "    mask = Image.new('RGBA', maxSize[2:],color=(255,255,255))\n",
    "    mask.paste(Image.open(im),(0,0))\n",
    "    ax.imshow( mask )\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    sns.despine(left=True,bottom=True)\n",
    "plt.savefig('../nsfigs/nsSpacesTest.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the secret blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in ['../outofsample/%s'%x for x in os.listdir('../outofsample/')]:\n",
    "    makeMeanMindSpace(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
